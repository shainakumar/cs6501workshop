Script started on 2026-01-22 03:19:43+00:00 [TERM="xterm-color" TTY="/dev/pts/0" COLUMNS="-1" LINES="-1"]
2026-01-22 03:19:58.689183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769051998.739733   22379 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769051998.757674   22379 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769051998.781545   22379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769051998.781605   22379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769051998.781613   22379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769051998.781620   22379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-22 03:19:58.788498: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
======================================================================
LangGraph Chat Agent with Conversation History
Using Llama 3.2 1B with Message API
======================================================================

Loading Llama model...
Using CUDA (NVIDIA GPU) for inference
Loading Llama model: meta-llama/Llama-3.2-1B-Instruct
This may take a moment on first run as the model is downloaded...
`torch_dtype` is deprecated! Use `dtype` instead!
Device set to use cuda
Llama model loaded successfully!

Creating LangGraph with conversation history support...
Graph created successfully!

Saving graph visualization...
Graph image saved to lg_graph.png

======================================================================
Chat session started. The assistant will remember your conversation.
Try asking follow-up questions to test the memory!
======================================================================

==================================================
Enter your text (or 'quit' to exit, 'verbose'/'quiet' to toggle tracing):
==================================================

> My name is Shaina

Processing with Llama (with conversation history)...

======================================================================
LLAMA 3.2 1B RESPONSE:
======================================================================
It's nice to meet you, Shaina! I'm happy to help you with any questions or concerns you may have. How can I assist you today?

==================================================
Enter your text (or 'quit' to exit, 'verbose'/'quiet' to toggle tracing):
==================================================

> What is my name?

Processing with Llama (with conversation history)...

======================================================================
LLAMA 3.2 1B RESPONSE:
======================================================================
You're referring to yourself, I presume? Your name is Shaina, correct?

==================================================
Enter your text (or 'quit' to exit, 'verbose'/'quiet' to toggle tracing):
==================================================

> quit
Goodbye!

Script done on 2026-01-22 03:21:20+00:00 [COMMAND_EXIT_CODE="0"]
