Script started on 2026-01-22 20:02:58+00:00 [TERM="xterm-color" TTY="/dev/pts/0" COLUMNS="-1" LINES="-1"]
2026-01-22 20:03:15.282791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769112195.414747   20689 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769112195.465360   20689 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769112195.557129   20689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769112195.557171   20689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769112195.557179   20689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769112195.557186   20689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-22 20:03:15.581034: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
======================================================================
LangGraph Multi-Agent Chat: Human + Llama + Qwen
======================================================================

Loading Llama model...
Using CUDA (NVIDIA GPU) for inference
Loading Llama model: meta-llama/Llama-3.2-1B-Instruct
This may take a moment on first run as the model is downloaded...
`torch_dtype` is deprecated! Use `dtype` instead!
Device set to use cuda
Llama model loaded successfully!

Loading Qwen model...
Using CUDA (NVIDIA GPU) for inference
Loading Qwen model: Qwen/Qwen2.5-0.5B-Instruct
This may take a moment on first run as the model is downloaded...
Device set to use cuda
Qwen model loaded successfully!

Creating LangGraph with multi-agent support...
Graph created successfully!

Saving graph visualization...
Graph image saved to lg_graph.png
[DEBUG] next=('get_user_input',) history_len=2
ðŸ”„ Resuming after restart...

======================================================================
Enter your text (or 'quit' to exit, 'verbose'/'quiet' to toggle tracing):
Tip: Start with 'Hey Qwen' or 'Hey Llama' to address a specific model
======================================================================

> quit
Goodbye!

Script done on 2026-01-22 20:04:03+00:00 [COMMAND_EXIT_CODE="0"]
